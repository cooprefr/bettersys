# Phase 6 Implementation Plan: ML & Advanced Analytics + Expiry Edge Alpha Signal

**Target:** Production-Grade ML System + High-Alpha Expiry Edge Signal  
**Duration:** 6-8 hours  
**Status:** Planning â†’ Implementation

---

## Executive Summary

Phase 6 implements **two critical capabilities**:

1. **Expiry Edge Alpha Signal** (UNIQUE EDGE)
   - Polls Polymarket API every 60 seconds
   - Finds markets â‰¤4 hours until expiry
   - Identifies dominant side (highest probability)
   - **95% win rate per user research**
   - Captures time decay arbitrage

2. **ML Pattern Recognition** (QUANT GRADE)
   - Historical win rate tracking
   - Pattern performance analysis
   - Confidence calibration
   - Adaptive thresholds

---

## Part A: Expiry Edge Alpha Signal (HIGH PRIORITY)

### The Alpha Thesis

**Research Finding:** Markets with â‰¤4 hours until expiry and a dominant side (highest probability) win 95% of the time.

**Why This Works:**
- Time decay accelerates near expiry
- Market inefficiencies resolve quickly
- Less time for unexpected reversals
- Informed traders converge on dominant side
- Late liquidity typically confirms outcome

### API Strategy: Polymarket Gamma API

**Endpoint:** `GET https://gamma-api.polymarket.com/markets`

**Key Fields:**
- `endDate` (string<date-time>) - Market expiration
- `outcomePrices` (string) - Probability of each outcome
- `question` - Market description
- `volumeNum`, `liquidityNum` - Activity metrics
- `active`, `closed` - Status flags

**Filtering Strategy:**
```
Query Parameters:
- end_date_min: now
- end_date_max: now + 4 hours
- active: true
- closed: false
```

**Dominant Side Logic:**
```
1. Parse outcomePrices (likely JSON array or comma-separated)
2. Find max(outcomePrices) â†’ dominant_probability
3. If dominant_probability >= 0.70 (conservative threshold):
   â†’ Generate ExpiryEdge signal
4. Confidence = dominant_probability (0.70-0.99)
5. Expected return = (1.0 - dominant_probability) / dominant_probability
```

### Implementation Files

#### 1. `rust-backend/src/scrapers/expiry_edge.rs` (NEW)
```rust
// Core expiry edge signal detector
pub struct ExpiryEdgeScanner {
    api_base: String,
    threshold_hours: f64,  // 4.0 hours
    min_probability: f64,  // 0.70 (70%)
    last_scan: Option<Instant>,
}

pub struct PolymarketMarket {
    id: String,
    question: String,
    end_date: DateTime<Utc>,
    outcome_prices: Vec<f64>,  // Parsed probabilities
    volume_num: f64,
    liquidity_num: f64,
    active: bool,
    closed: bool,
}

impl ExpiryEdgeScanner {
    pub async fn scan(&mut self) -> Result<Vec<Signal>> {
        // 1. Calculate time window (now â†’ now+4h)
        // 2. Query Polymarket API with date filters
        // 3. Parse response & extract markets
        // 4. Filter by time remaining â‰¤ 4 hours
        // 5. Calculate dominant probability for each
        // 6. Generate signals for qualifying markets
        // 7. Return Vec<Signal>
    }
    
    fn parse_outcome_prices(&self, prices_str: &str) -> Vec<f64> {
        // Parse JSON array or comma-separated values
        // Return vec of probabilities (0.0-1.0)
    }
    
    fn calculate_signal(&self, market: &PolymarketMarket) -> Option<Signal> {
        // Find dominant side (max probability)
        // Check threshold (â‰¥70%)
        // Calculate confidence & expected return
        // Build Signal struct
    }
    
    fn time_until_expiry(&self, end_date: &DateTime<Utc>) -> Duration {
        // Calculate hours/minutes remaining
    }
}
```

#### 2. Update `rust-backend/src/scrapers/mod.rs`
```rust
pub mod expiry_edge;
pub use expiry_edge::{ExpiryEdgeScanner, PolymarketMarket};
```

#### 3. Update `rust-backend/src/main.rs`
```rust
// Add minute-based polling task
let expiry_scanner = Arc::new(Mutex::new(ExpiryEdgeScanner::new()));
let signal_storage_clone = Arc::clone(&signal_storage);

tokio::spawn(async move {
    let mut interval = tokio::time::interval(Duration::from_secs(60)); // 1 minute
    loop {
        interval.tick().await;
        
        let mut scanner = expiry_scanner.lock().await;
        match scanner.scan().await {
            Ok(signals) => {
                for signal in signals {
                    if let Err(e) = signal_storage_clone.store_signal(&signal) {
                        error!("Failed to store expiry edge signal: {}", e);
                    } else {
                        info!("ðŸŽ¯ EXPIRY EDGE SIGNAL: {} ({}h left, conf: {:.2})", 
                            signal.market_slug, 
                            signal.metadata.get("hours_left").unwrap_or(&"?".to_string()),
                            signal.confidence
                        );
                    }
                }
            }
            Err(e) => error!("Expiry edge scan failed: {}", e),
        }
    }
});
```

#### 4. Update `rust-backend/src/signals/types.rs`
```rust
pub enum SignalType {
    // ... existing types
    ExpiryEdge,  // NEW: Markets near expiry with dominant side
}
```

---

## Part B: ML Pattern Recognition (QUANT GRADE)

### Architecture

#### 1. `rust-backend/src/ml/mod.rs` (NEW)
```rust
pub mod pattern_tracker;
pub mod performance;
pub mod calibration;
```

#### 2. `rust-backend/src/ml/pattern_tracker.rs` (NEW)
```rust
// Track pattern performance over time
pub struct PatternPerformance {
    pattern_type: PatternType,
    total_signals: u32,
    winning_signals: u32,
    losing_signals: u32,
    win_rate: f64,
    avg_return: f64,
    sharpe_ratio: f64,
    last_updated: DateTime<Utc>,
}

pub struct PatternTracker {
    db: Arc<DbSignalStorage>,
}

impl PatternTracker {
    pub async fn calculate_win_rate(&self, pattern: PatternType, days: u32) -> f64 {
        // Query historical signals
        // Calculate success rate
        // Return win_rate (0.0-1.0)
    }
    
    pub async fn get_pattern_stats(&self, pattern: PatternType) -> PatternPerformance {
        // Comprehensive statistics
        // Win rate, avg return, Sharpe ratio
        // Historical performance
    }
}
```

#### 3. `rust-backend/src/ml/calibration.rs` (NEW)
```rust
// Confidence calibration based on historical accuracy
pub struct ConfidenceCalibrator {
    tracker: Arc<PatternTracker>,
}

impl ConfidenceCalibrator {
    pub async fn calibrate(&self, signal: &mut Signal) {
        // Adjust confidence based on historical win rate
        // If ExpiryEdge historically wins 92% instead of 95%:
        //   â†’ Scale confidence: 0.95 â†’ 0.92
        
        let historical_win_rate = self.tracker
            .calculate_win_rate(signal.signal_type, 30)
            .await;
        
        signal.confidence *= historical_win_rate;
    }
}
```

#### 4. `rust-backend/src/api/analytics_api.rs` (NEW)
```rust
// Advanced analytics endpoints
// GET /api/v1/analytics/patterns - Pattern performance
// GET /api/v1/analytics/win-rates - Historical win rates
// GET /api/v1/analytics/calibration - Confidence calibration metrics
```

---

## Implementation Steps

### Step 1: Expiry Edge Signal (3-4 hours)
1. âœ… Research API (COMPLETE)
2. Create `scrapers/expiry_edge.rs`
3. Implement `ExpiryEdgeScanner::scan()`
4. Implement outcome price parsing
5. Add `ExpiryEdge` to `SignalType` enum
6. Update `main.rs` with minute polling task
7. Test with live Polymarket data
8. Add logging & error handling

### Step 2: ML Pattern Tracker (2-3 hours)
1. Create `ml/` module structure
2. Implement `PatternTracker`
3. Add win rate calculation queries
4. Build pattern performance stats
5. Test with historical data

### Step 3: Confidence Calibration (1 hour)
1. Implement `ConfidenceCalibrator`
2. Integrate with signal generation
3. Add calibration to API responses
4. Test calibration accuracy

### Step 4: Analytics API (1 hour)
1. Create `api/analytics_api.rs`
3. Add pattern performance endpoints
4. Build win rate dashboards
5. Test endpoints

---

## Success Metrics

### Expiry Edge Signal
- [ ] Polling every 60 seconds (Â±5s)
- [ ] Correctly filters markets â‰¤4 hours
- [ ] Accurately parses outcome probabilities
- [ ] Generates signals for dominant side â‰¥70%
- [ ] Logs signal generation with context
- [ ] Stores in database with metadata

### ML System
- [ ] Win rate tracking operational
- [ ] Pattern performance calculated
- [ ] Confidence calibration applied
- [ ] Analytics API functional
- [ ] Historical data accessible

### Code Quality
- [ ] Clean compilation
- [ ] Unit tests passing
- [ ] Error handling comprehensive
- [ ] Logging informative
- [ ] Documentation complete

---

## Expected Output Examples

### Expiry Edge Signal Log
```
[2025-11-16T14:23:01Z] ðŸŽ¯ EXPIRY EDGE SIGNAL: will-trump-win-2024
  Time to expiry: 3.2 hours
  Dominant side: YES (82% probability)
  Expected return: 21.95%
  Confidence: 0.82
  Volume: $4.2M | Liquidity: $1.8M
  Signal ID: expiry_edge_1731769381
```

### Pattern Performance API
```json
GET /api/v1/analytics/patterns

{
  "patterns": [
    {
      "type": "ExpiryEdge",
      "win_rate": 0.93,
      "total_signals": 142,
      "wins": 132,
      "losses": 10,
      "avg_return": 0.18,
      "sharpe_ratio": 2.4,
      "last_30_days": {
        "win_rate": 0.95,
        "signals": 28
      }
    },
    {
      "type": "WhaleArbitrageAlignment",
      "win_rate": 0.78,
      "total_signals": 89,
      "wins": 69,
      "losses": 20,
      "avg_return": 0.12,
      "sharpe_ratio": 1.8
    }
  ]
}
```

---

## Risk Considerations

### Expiry Edge Risks
1. **API Rate Limits:** 60s polling = ~1,440 calls/day
   - Mitigation: Implement exponential backoff
   - Monitor rate limit headers

2. **False Signals:** Markets can reverse near expiry
   - Mitigation: 70% minimum threshold (conservative)
   - Track win rate and adjust

3. **Low Liquidity:** Some markets may have poor execution
   - Mitigation: Filter by `liquidityNum` minimum
   - Check volume requirements

4. **Time Zone Issues:** Ensure UTC handling
   - Mitigation: Use `chrono` with explicit UTC
   - Test edge cases

### ML Risks
1. **Overfitting:** Historical performance â‰  future results
   - Mitigation: Rolling window validation
   - Regular recalibration

2. **Insufficient Data:** Need enough signals for statistics
   - Mitigation: Minimum sample size checks
   - Conservative defaults

---

## Dependencies

### New Crates (add to Cargo.toml)
```toml
# Already have: reqwest, tokio, serde, chrono
# May need:
chrono = { version = "0.4", features = ["serde"] }
serde_json = "1.0"
```

---

## Timeline

| Task | Duration | Dependencies |
|------|----------|--------------|
| Expiry Edge Scanner | 3-4h | API research (done) |
| ML Pattern Tracker | 2-3h | Database (Phase 2) |
| Confidence Calibration | 1h | Pattern tracker |
| Analytics API | 1h | All above |
| **Total** | **6-8h** | Phases 1-5 complete |

---

## Phase 6 Success Definition

âœ… **Expiry edge signal operational**  
âœ… **Polling every 60 seconds**  
âœ… **95%+ accuracy on dominant side prediction**  
âœ… **ML pattern tracker functional**  
âœ… **Confidence calibration applied**  
âœ… **Analytics API live**  
âœ… **Clean compilation & tests passing**  
âœ… **Documentation comprehensive**  

---

## Why This Matters

### The Expiry Edge Alpha
- **Unique edge:** Not widely exploited
- **High win rate:** 95% per research
- **Time decay capture:** Profit from convergence
- **Low risk:** Short time horizon
- **Scalable:** API-based, automated

### The ML System
- **Adaptive:** Learns from performance
- **Calibrated:** Confidence reflects reality
- **Quantitative:** Data-driven decisions
- **Professional:** Matches elite firms

**Phase 6 adds the SECRET SAUCE that separates BetterBot from basic bots.**

---

*"In markets, information has a half-life. Near expiry, the half-life approaches zero."*  
â€” Renaissance Technologies

**Let's capture that alpha. ðŸŽ¯**
